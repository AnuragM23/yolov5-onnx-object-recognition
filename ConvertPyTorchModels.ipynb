{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c7dacd",
   "metadata": {},
   "source": [
    "# Convert PyTorch models to Open Neural Network Exchange format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb18f1b",
   "metadata": {},
   "source": [
    "**Converting PyTorch models to the Open Neural Network Exchange (ONNX) format offers several benefits, including portability, interoperability, and the ability to deploy models across various frameworks and platforms. Here are some reasons for converting PyTorch models to ONNX:**\n",
    "\n",
    "- ONNX is designed to be a common format that multiple deep learning frameworks (e.g., TensorFlow, PyTorch, MXNet) can support. By converting a PyTorch model to ONNX, you enable interoperability and allow for the seamless use of the model in other frameworks.\n",
    "- Once a model is in the ONNX format, it becomes framework-agnostic. You can use it with any framework that supports ONNX, reducing the lock-in to a specific deep learning framework.\n",
    "- ONNX models can be deployed on a variety of platforms, including cloud-based services, edge devices, and embedded systems. The ONNX Runtime is an inference engine optimized for running ONNX models efficiently on various hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed828660",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def3451f",
   "metadata": {},
   "source": [
    "## 1. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a29e4602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.22.2 in e:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 3)) (1.24.3)\n",
      "Collecting opencv-python>=4.1.1 (from -r requirements.txt (line 4))\n",
      "  Obtaining dependency information for opencv-python>=4.1.1 from https://files.pythonhosted.org/packages/38/d2/3e8c13ffc37ca5ebc6f382b242b44acb43eb489042e1728407ac3904e72f/opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl.metadata\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting torch>=1.8.0 (from -r requirements.txt (line 5))\n",
      "  Downloading torch-2.0.1-cp311-cp311-win_amd64.whl (172.3 MB)\n",
      "     -------------------------------------- 172.3/172.3 MB 1.8 MB/s eta 0:00:00\n",
      "Collecting torchvision>=0.9.0 (from -r requirements.txt (line 6))\n",
      "  Downloading torchvision-0.15.2-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "     -------- ------------------------------- 0.3/1.2 MB 7.9 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 0.8/1.2 MB 9.7 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 0.9/1.2 MB 7.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.1/1.2 MB 6.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.2/1.2 MB 5.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=1.1.4 in e:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 10)) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in e:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 11)) (0.12.2)\n",
      "Collecting onnx>=1.10.0 (from -r requirements.txt (line 15))\n",
      "  Obtaining dependency information for onnx>=1.10.0 from https://files.pythonhosted.org/packages/03/49/7263b3806ffebd3c967341986df32a5e62b2fa78beca2cdf9516d876b3fc/onnx-1.14.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading onnx-1.14.1-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: filelock in e:\\anaconda\\lib\\site-packages (from torch>=1.8.0->-r requirements.txt (line 5)) (3.9.0)\n",
      "   ---------------------------------------- 38.1/38.1 MB 3.0 MB/s eta 0:00:00\n",
      "Downloading onnx-1.14.1-cp311-cp311-win_amd64.whl (13.3 MB)\n",
      "   ---------------------------------------- 13.3/13.3 MB 3.6 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python, onnx, torch, torchvision\n",
      "Successfully installed onnx-1.14.1 opencv-python-4.8.1.78 torch-2.0.1 torchvision-0.15.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a69cafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in e:\\anaconda\\lib\\site-packages (1.14.1)\n",
      "Requirement already satisfied: numpy in e:\\anaconda\\lib\\site-packages (from onnx) (1.24.3)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in e:\\anaconda\\lib\\site-packages (from onnx) (4.24.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in e:\\anaconda\\lib\\site-packages (from onnx) (4.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8f3a3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in e:\\anaconda\\lib\\site-packages (2.0.1)\n",
      ".....",
      "Requirement already satisfied: mpmath>=0.19 in e:\\anaconda\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4395ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dec69f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2b9673",
   "metadata": {},
   "source": [
    "## 1. Clone Ultralytics/yolov5 Repository\n",
    "[https://github.com/ultralytics/yolov5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e00277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r'E:\\Source Codes\\AIML\\ObjDtectionUsingYOLOv5andPython' # give/your/project/path/here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4abef1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: E:\\Source Codes\\AIML\\ObjDtectionUsingYOLOv5andPython\n"
     ]
    }
   ],
   "source": [
    "os.chdir(directory)\n",
    "print(\"Current directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32efcbb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Source Codes\\AIML\\ObjDtectionUsingYOLOv5andPython\\yolov5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5\n",
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2f18f2",
   "metadata": {},
   "source": [
    "## 2. Download the YOLOv5 PyTorch Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baea3898",
   "metadata": {},
   "source": [
    "**Note:** You need to have `WGet` installed in your system if you're working locally and not on a cloud environment like GoogleCollab\n",
    "[https://eternallybored.org/misc/wget/]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1be3015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd models\n",
    "# !wget https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5n.pt -nv\n",
    "# !wget https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt -nv\n",
    "# !wget https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5m.pt -nv\n",
    "# !wget https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5l.pt -nv\n",
    "# !wget https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5x.pt -nv\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155d173d",
   "metadata": {},
   "source": [
    "**For a Python based solution, we can use `urllib` by using `import urllib.request`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54031242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: E:\\Source Codes\\AIML\\ObjDtectionUsingYOLOv5andPython\n"
     ]
    }
   ],
   "source": [
    "os.chdir(directory)\n",
    "print(\"Current directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75c2851f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Source Codes\\AIML\\ObjDtectionUsingYOLOv5andPython\\models\n",
      "Downloaded yolov5n.pt\n",
      "Downloaded yolov5s.pt\n",
      "Downloaded yolov5m.pt\n",
      "Downloaded yolov5l.pt\n",
      "Downloaded yolov5x.pt\n",
      "Downloads complete.\n"
     ]
    }
   ],
   "source": [
    "%cd models\n",
    "urls = [\n",
    "    \"https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5n.pt\",\n",
    "    \"https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt\",\n",
    "    \"https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5m.pt\",\n",
    "    \"https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5l.pt\",\n",
    "    \"https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5x.pt\"\n",
    "]\n",
    "\n",
    "for url in urls:\n",
    "    filename = url.split(\"/\")[-1]  # Extract the filename from the URL\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "    print(f\"Downloaded {filename}\")\n",
    "\n",
    "print(\"Downloads complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a608a506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Source Codes\\AIML\\ObjDtectionUsingYOLOv5andPython\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34afa8",
   "metadata": {},
   "source": [
    "## 3. Export these models to ONNX format\n",
    "\n",
    "***(The default input size is 640x640)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17ba9457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Obtaining dependency information for ultralytics from https://files.pythonhosted.org/packages/76/15/ade2c76a3d2d6235744ef76b9da73dc89d693d4ceffd9ce361773da9c053/ultralytics-8.0.192-py3-none-any.whl.metadata\n",
      "  Downloading ultralytics-8.0.192-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in e:\\anaconda\\lib\\site-packages (from ultralytics) (3.7.1)\n",
      ".....",
      "Requirement already satisfied: py-cpuinfo in e:\\anaconda\\lib\\site-packages (from ultralytics) (8.0.0)\n",
      "Collecting thop>=0.1.1 (from ultralytics)\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.0.5)\n",
      ".....",
      "Requirement already satisfied: mpmath>=0.19 in e:\\anaconda\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Downloading ultralytics-8.0.192-py3-none-any.whl (616 kB)\n",
      "   ---------------------------------------- 0.0/616.5 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 61.4/616.5 kB 3.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 174.1/616.5 kB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 368.6/616.5 kB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  614.4/616.5 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 616.5/616.5 kB 3.5 MB/s eta 0:00:00\n",
      "Installing collected packages: thop, ultralytics\n",
      "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.192\n",
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=E:\\Source Codes\\AIML\\ObjDtectionUsingYOLOv5andPython\\yolov5\\data\\coco128.yaml, weights=['models/yolov5n.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx']\n",
      "fatal: cannot change to 'E:\\Source': No such file or directory\n",
      "YOLOv5  2023-10-4 Python-3.11.4 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from models\\yolov5n.pt with output shape (1, 25200, 85) (3.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.0s, saved as models\\yolov5n.onnx (7.6 MB)\n",
      "\n",
      "Export complete (1.8s)\n",
      "Results saved to \u001b[1mE:\\Source Codes\\AIML\\ObjDtectionUsingYOLOv5andPython\\models\u001b[0m\n",
      "Detect:          python detect.py --weights models\\yolov5n.onnx \n",
      "Validate:        python val.py --weights models\\yolov5n.onnx \n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'models\\yolov5n.onnx')  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=E:\\Source Codes\\AIML\\ObjDtectionUsingYOLOv5andPython\\yolov5\\data\\coco128.yaml, weights=['models/yolov5s.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx']\n",
      "fatal: cannot change to 'E:\\Source': No such file or directory\n",
      "YOLOv5  2023-10-4 Python-3.11.4 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from models\\yolov5s.pt with output shape (1, 25200, 85) (14.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.6s, saved as models\\yolov5s.onnx (28.0 MB)\n",
      "\n",
      "Export complete (2.6s)\n",
      "Results saved to \u001b[1mE:\\Source Codes\\AIML\\ObjDtectionUsingYOLOv5andPython\\models\u001b[0m\n",
      "Detect:          python detect.py --weights models\\yolov5s.onnx \n",
      "Validate:        python val.py --weights models\\yolov5s.onnx \n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'models\\yolov5s.onnx')  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=E:\\Source Codes\\AIML\\ObjDtectionUsingYOLOv5andPython\\yolov5\\data\\coco128.yaml, weights=['models/yolov5m.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx']\n",
      "fatal: cannot change to 'E:\\Source': No such file or directory\n",
      "YOLOv5  2023-10-4 Python-3.11.4 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from models\\yolov5m.pt with output shape (1, 25200, 85) (40.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  3.3s, saved as models\\yolov5m.onnx (81.2 MB)\n",
      "\n",
      "Export complete (5.6s)\n",
      "Results saved to \u001b[1mE:\\Source Codes\\AIML\\ObjDtectionUsingYOLOv5andPython\\models\u001b[0m\n",
      "Detect:          python detect.py --weights models\\yolov5m.onnx \n",
      "Validate:        python val.py --weights models\\yolov5m.onnx \n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'models\\yolov5m.onnx')  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=E:\\Source Codes\\AIML\\ObjDtectionUsingYOLOv5andPython\\yolov5\\data\\coco128.yaml, weights=['models/yolov5l.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx']\n",
      "fatal: cannot change to 'E:\\Source': No such file or directory\n",
      "YOLOv5  2023-10-4 Python-3.11.4 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5l summary: 367 layers, 46533693 parameters, 0 gradients\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from models\\yolov5l.pt with output shape (1, 25200, 85) (89.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  6.6s, saved as models\\yolov5l.onnx (178.0 MB)\n",
      "\n",
      "Export complete (11.0s)\n",
      "Results saved to \u001b[1mE:\\Source Codes\\AIML\\ObjDtectionUsingYOLOv5andPython\\models\u001b[0m\n",
      "Detect:          python detect.py --weights models\\yolov5l.onnx \n",
      "Validate:        python val.py --weights models\\yolov5l.onnx \n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'models\\yolov5l.onnx')  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=E:\\Source Codes\\AIML\\ObjDtectionUsingYOLOv5andPython\\yolov5\\data\\coco128.yaml, weights=['models/yolov5x.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx']\n",
      "fatal: cannot change to 'E:\\Source': No such file or directory\n",
      "YOLOv5  2023-10-4 Python-3.11.4 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5x summary: 444 layers, 86705005 parameters, 0 gradients\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from models\\yolov5x.pt with output shape (1, 25200, 85) (166.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  14.2s, saved as models\\yolov5x.onnx (331.2 MB)\n",
      "\n",
      "Export complete (23.0s)\n",
      "Results saved to \u001b[1mE:\\Source Codes\\AIML\\ObjDtectionUsingYOLOv5andPython\\models\u001b[0m\n",
      "Detect:          python detect.py --weights models\\yolov5x.onnx \n",
      "Validate:        python val.py --weights models\\yolov5x.onnx \n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'models\\yolov5x.onnx')  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/export.py --weights models/yolov5n.pt --include onnx\n",
    "!python yolov5/export.py --weights models/yolov5s.pt --include onnx\n",
    "!python yolov5/export.py --weights models/yolov5m.pt --include onnx\n",
    "!python yolov5/export.py --weights models/yolov5l.pt --include onnx\n",
    "!python yolov5/export.py --weights models/yolov5x.pt --include onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c6cc20",
   "metadata": {},
   "source": [
    "*Add the flag `--imsz` to export for custom input size.*\n",
    "### `!python export.py --weights models/yolov5n.pt --include onnx --imsz 320 320`\n",
    "\n",
    "*Add the flag `--dyanamic` for dynamic input size. Compatible with ONNX runtime.*\n",
    "### `!python export.py --weights models/yolov5n.pt --include onnx --dynamic`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadd1bd6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675b8542",
   "metadata": {},
   "source": [
    "## For a GoogleCollab environment you can also download the ONNX files\n",
    "> from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f06e03",
   "metadata": {},
   "source": [
    "#### `files.download('models/yolov5n.onnx')`\n",
    "#### `files.download('models/yolov5s.onnx')`\n",
    "#### `files.download('models/yolov5m.onnx')`\n",
    "#### `files.download('models/yolov5l.onnx')`\n",
    "#### `files.download('models/yolov5x.onnx')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1220e2da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
